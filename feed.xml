<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jongbokwvn.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jongbokwvn.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-30T12:53:52+00:00</updated><id>https://jongbokwvn.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">[review] The First Law of Complexodynamics</title><link href="https://jongbokwvn.github.io/blog/2025/distill/" rel="alternate" type="text/html" title="[review] The First Law of Complexodynamics"/><published>2025-04-30T00:00:00+00:00</published><updated>2025-04-30T00:00:00+00:00</updated><id>https://jongbokwvn.github.io/blog/2025/%08distill</id><content type="html" xml:base="https://jongbokwvn.github.io/blog/2025/distill/"><![CDATA[<h2 id="backgrounds">Backgrounds</h2> <ul> <li><strong>열역학 제 2법칙 (the second law of thermodynamics)</strong> <ul> <li>닫힌 계에서 엔트로피는 시간이 지남에 따라 maximum value를 달성할 때까지 증가하거나 일정하게 유지됨</li> <li>닫힌 계에서, 시스템은 시간이 지남에 따라 ‘더 많은 방법으로 존재할 수 있는 상태’로 자연스럽게 이동한다는 법칙 <ul> <li>시간의 흐름은 무질서의 증가를 동반하게 됨</li> </ul> </li> </ul> </li> <li><strong>엔트로피</strong> <ul> <li>시스템의 또 다른 성질 (another property of the system)</li> <li>시스템이 얼마나 무작위적이고 일반적이며 무질서한지를 수치화한 것</li> <li>$ \mathcal S = k_{\mathcal B}\ln \Omega $: 가능한 미시상태(microstates)의 수에 대한 로그</li> </ul> </li> <li><strong>Kolmogorov Complexity</strong> <ul> <li>시스템의 복잡성(Complexity)을 측정하는 방법</li> <li>주어진 객체를 생성하는 가장 짧은 프로그램의 길이</li> <li>$ \mathcal K(\mathbf x) = \min_\mathcal p {|p| : U(\mathcal p) = \mathbf x} $</li> </ul> </li> <li><strong>Sophistication</strong> <ul> <li>데이터를 생성하는 데 필요한 가장 단순한 구조적 모델의 복잡도 <ul> <li>데이터에 포함된 정보 중 구조적인 정보와 무작위적인 정보를 구분하기 위해 제안</li> </ul> </li> <li>‘복잡성’ 계산에 있어 구조(structure)와 무작위(randomness)를 구분하기 위한 개념으로, kolmogorov complexity는 이 둘을 구분하지 못함</li> <li><strong>equation</strong> \(\text{Soph }_\mathbf c (\mathbf x) = \min \{ \mathcal K(\mathcal S) \| \mathbf x \in \mathcal S \text{ and } \mathcal K(\mathcal S) + \mathcal K(\mathbf x \| \mathcal S) \leq \mathcal K(\mathbf x) + \mathbf c \}\) <ul> <li><strong>annotation</strong> <ul> <li>$ \mathbf x \in \mathcal S $: 유한집합 $ \mathcal S $에 속한 문자열 $ \mathbf x $</li> <li>$ \mathbf c $: 중요도 상수 (significance constant)</li> <li>$ \mathcal K(\mathcal S) $: 유한집합 $ \mathcal S $의 kolmogorov complexity (유한집합을 기술하는 가장 짧은 프로그램의 길이)</li> <li>$ \mathcal K(\mathbf x | \mathcal S) $: 유한집합의 정보를 알고 있을 때 $ \mathbf x $를 특정하기 위해 추가로 필요한 정보량</li> </ul> </li> <li>sophistication = $ \mathbf x $를 설명하는 효율적인 모델 $ \mathcal S $를 찾는 과정에서, $ \mathbf x $를 $ \mathcal S $를 통해 설명하는 것이 직접 $ \mathbf x $를 설명하는 것만큼 효율적인 모델 들 중에서 가장 단순한 모델의 복잡도</li> <li>kolmogorov complexity와 달리 $ \mathbf x $가 속한 집합 $ \mathcal S $의 complexity를 활용하여 $ \mathbf x $의 complexity를 계산</li> </ul> </li> </ul> </li> </ul> <hr/> <h2 id="questions--answers">Questions &amp; Answers</h2> <p><strong>Question:</strong></p> <p>왜 열량 $ \delta Q $을 순간온도 $ T $로 나눈 값을 적분한 것이, 시스템의 ‘무질서도’, ‘일반성’, ‘무작위성’이라는 엔트로피 개념을 대표할 수 있는가?</p> \[\triangle S = \int{\delta Q\over T}\] <ul> <li>$ \delta $: inexact differential. 경로함수의 미소량</li> <li>$ Q $: 시스템이 외부로부터 받는 열 에너지</li> <li>$ T $: 열이 전달되는 경로 상의 순간 온도 (state variable에 해당)</li> </ul> <p><strong>Answer:</strong></p> <p>에너지는 시스템 내에서 어떤 온도에서 주고받는지가 매우 중요</p> <p>열량을 온도로 정규화함으로서, 추가적으로 주어지는 열이 시스템이 미치는 효과를 상대적으로 측정 가능</p> <ul> <li>고온의 환경에서, 추가적으로 주어지는 열은 시스템의 무질서 증가를 유발하지만, 그 정도는 상대적으로 작은 반면,</li> <li>저온의 환경에서, 추가적으로 주어지는 열은 시스템의 무질서 증가를 유발하며, 그 정도는 상대적으로 클 것이다.</li> </ul> <p>즉, 열량을 온도로 정규화함으로써, 주어진 에너지가 미시상태를 얼마나 증가시키는가를 측정할 수 있게 되는 것</p> <ul> <li>$ {\delta Q \over T} $: 시스템의 미시적 복잡성 증대량을 표현하는 정규화된 양</li> </ul> <hr/> <p><strong>Question:</strong></p> <p>열역학(thermodynamics) 관점에서의 ‘엔트로피’와 통계역학(statistical mechanics) 관점에서의 ‘엔트로피’ 간의 관련성</p> <p><strong>Answer:</strong></p> <p>definition of boltzmann entropy</p> <ul> <li>엔트로피 = 가능한 미시상태 수의 로그에 비례하는 양</li> <li>$ S = k \ln \Omega $ <ul> <li>$ k $: boltzmann 상수</li> <li>$ \Omega $: 가능한 미시상태 수</li> </ul> </li> </ul> <p>열량이 시스템에 주입되면, 입자들이 가질 수 있는 에너지 조합은 지수적으로 증가</p> <ul> <li>에너지가 배분되는 방식 하나하나가 하나의 미시상태를 정의함</li> <li>결국 미시상태 수는 주어진 열량 하에서 시스템이 가질 수 있는 가능한 구성(configuration) 수를 의미하며, $ \Omega $가 크다는 것은 시스템이 많은 다양한 방식으로 현재 상태를 유지할 수 있음을 의미</li> </ul> <p>많은 미시상태를 가지는 시스템은 다양한 내부 구성이 가능하다는 점에서 시스템의 복잡성(complexity)으로 나타남</p> <hr/> <h2 id="abstract">Abstract</h2> <ul> <li><strong>main question</strong> <ul> <li>Why does ‘complexity’ or ‘interestingness’ of physical systems seem to increase with time and then hit a maximum and decrease, in contrast to the entropy, which of course increases monotonically? <ul> <li>물리계에서 ‘복잡도’는 시간의 흐름과 함께 최대치를 달성하고 나서 감소하는 경향을 보이는 반면, 엔트로피는 단조적으로 증가하는 경향을 보이는데, 그 이유는 무엇인가?</li> </ul> </li> </ul> </li> <li><strong>main answer</strong> <ul> <li>엔트로피는 단순히 ‘더 일반적인 미시상태(micro-state)로의 경향’을 표현하는 공리(tautology)에 가까우며, 본질적인 질문은 ‘왜 초기 상태에서의 엔트로피는 낮은가?’에 해당</li> <li>물리계에서 관찰되는 시간의 흐름에 따른 구조적 복잡성을 설명할 수 있는 수학적 지표의 필요성 <ul> <li>Kolmogorov complexity에 resource-bounded를 적용한 ‘Complextropy’를 제안하고, 샘플러와 복원기 두 알고리즘 모두에 계산 시간 제한을 걸면, 그 지표가 바로 원하는 물리계에서의 구조적 복잡성을 재현할 것이라는 추측(conjecture)을 제시</li> </ul> </li> </ul> </li> </ul> <hr/> <h2 id="content">Content</h2> <p><strong>(main question)</strong></p> <p>Why does ‘complexity’ or ‘interestingness’ of physical systems seem to increase with time and then hit a maximum and decrease, in contrast to the entropy, which of course increases monotonically?</p> <ul> <li>물리계에서 ‘복잡도’는 시간의 흐름과 함께 최대치를 달성하고 나서 감소하는 경향을 보이는 반면, 엔트로피는 단조적으로 증가하는 경향을 보이는데, 그 이유는 무엇인가?</li> </ul> <p><strong>(sub-question - part 1)</strong></p> <p>열역학 제 2법칙: 고립된 시스템은 시간이 지남에 따라 가능한 미시상태 수가 많은 일반적인 상태(generic state), 즉 엔트로피가 높은 상태로 진화하게 되는데, 이건 ‘<em>대부분의 상태로 시스템이 진화한다</em>‘는 명제와 논리상으로 동일</p> <ul> <li>‘엔트로피는 왜 단조적으로 증가하는가?’에 대한 질문보다,</li> <li>‘<strong>왜 초기 상태에서의 엔트로피는 낮은가</strong>‘에 대해 질문이 필요 (하지만 미스터리한 영역에 해당하므로, 주어진 명제로 수용하고 있음)</li> </ul> <p><strong>(sub-question - part 2)</strong></p> <p>Sean의 주장에 따르면, 닫힌 물리계에서 엔트로피는 단조적으로 증가하더라도, 시스템의 ‘complexity’ 혹은 ‘interesting’은 단조적으로 증가하지만은 않는다고 주장. 왜 그런 것인가?</p> <p><img src="/assets/img/250430.png" alt="Complexity vs Entropy over time"/></p> <ul> <li>초기 상태: 가능한 미시상태의 수가 적다는 점에서 시스템의 복잡성은 0에 수렴</li> <li>후기 상태: 가능한 미시상태의 수가 증가함에 따라 시스템이 평형(equilibrium)을 달성한다는 점에서 시스템의 복잡성은 0에 수렴</li> <li>중간 상태: 가능한 미시상태의 수가 증가하는 과정에서 시스템 평형을 달성하기 위한 상호작용이 발생함에 따라 시스템의 복잡성은 증가</li> </ul> <p>하지만 여기서,</p> <ul> <li>‘complexity’란 무엇인가? 하는 질문은 제기됨. <ul> <li>Sophistication의 개념을 통해 complexity를 정의할 수 있을 것</li> </ul> </li> </ul> <ol> <li>Kolmogorov complexity의 개념을 활용하여 entropy를 설명할 수 있음 <ul> <li>deterministic system에서 system의 complexity는 시간에 대해서 로그적으로 증가하게 됨 <ul> <li>deterministic system에서 state는 initial condition과 time step t에 의존하기 때문</li> <li>하지만 entropy 증가를 설명하기에는 kolmogorov complexity가 너무 느리게 증가</li> </ul> </li> <li>probabilistic system 혹은 resource-bounded kolmogorov complexity 개념을 활용한다면, entropy의 선형적 증가를 설명할 수 있음</li> </ul> </li> <li>Kolmogorov complexity의 개념을 활용하여 complextropy에 대해 설명 (kolmogorov complexity와 구별되는 complexity의 개념) <ul> <li>Kolmogorov complexity는 복잡성(complextropy) 계산에 있어 구조적 복잡성 계산 혹은 무작위적 복잡성 계산을 구분하여 계산하는 것이 불가능</li> <li>Sophistication은 단순, 난수 두 극단에서는 작고, 그러지 않은 단계에서는 커지는 척도에 해당하지만,</li> <li>여전히 deterministic system과 probabilistic system에서 probability transition function이 주어진 경우, complextropy가 logarithmical하게 증가한다는 점에서 여전히 동역학적 complextropy를 설명하는 것이 제한됨.</li> </ul> </li> <li>Complextropy with computationl resource bounds <ul> <li>computational resource bound를 적용한 n-bits 문자열 $ \mathbf x $의 complextropy <ul> <li>$ n \log n $ 시간에 작동하는 가장 짧은 프로그램 길이를 complextropy로 정의하되, 그 프로그램은 $ \mathcal S $에서 균등 샘플(uniform sample)을 생성하고, Oracle이 있더라도 $ \mathbf x $를 재생성하는 데 $ \log_2|\mathcal S| - c $ 비트가 필요해야 한다. <ul> <li>$ n \log n $ 시간: 시간 자원 제약을 통한 효율성 조건</li> <li>샘플 조건: 프로그램이 $ \mathcal S $에서 균등 샘플을 생성 <ul> <li>$ \mathbf x $가 $ \mathcal S $에서 전형적(generic)으로 보이도록 강제</li> </ul> </li> <li>복원 조건: Oracle이 있더라도 $ \mathbf x $를 재생성하는데 적어도 $ \log_2|\mathcal S| $의 비트가 필요</li> </ul> </li> <li>이중 효율성 제약 부과 <ul> <li>샘플조건과 복원조건에 동일한 시간 제약을 통해 중간 단계(intermediate)에서의 복잡성을 설명 가능</li> </ul> </li> </ul> </li> <li>The First Law of Complexodynamics <ul> <li>효율성 제약 하에서 complexotropy는 초기에는 작고, 중간에는 커지며, 종기에는 다시 작아진다</li> <li>증명되지 않았지만, 추측(conjecture)을 통해 증명 가능</li> </ul> </li> </ul> </li> </ol> <hr/> <h2 id="insight">Insight</h2> <ul> <li>엔트로피와 복잡성을 구분 <ul> <li>complextropy를 통해 엔트로피와 구분되는 물리계에서의 복잡성 특이점을 포착하고 이를 수학적으로 모델링하려는 시도</li> </ul> </li> <li>자원 제약의 물리학적 해석 <ul> <li>복잡성을 계산 가능한 함수로 모델링함으로써 물리적 복잡성에 따른 제약을 계산</li> <li>엔트로피 = 정보 (가능한 미시상태의 수)</li> <li>복잡성 = 자원제한 정보</li> </ul> </li> </ul>]]></content><author><name>Scott Aaronson</name></author><category term="distill"/><category term="formatting"/><summary type="html"><![CDATA[About the complexity and entropy of the model based on Kolmogorov Complexity]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://jongbokwvn.github.io/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://jongbokwvn.github.io/blog/2025/plotly</id><content type="html" xml:base="https://jongbokwvn.github.io/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://jongbokwvn.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://jongbokwvn.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://jongbokwvn.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024[[read-time]] min read We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://jongbokwvn.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://jongbokwvn.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://jongbokwvn.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[<h3>External Posts on Your al-folio Blog</h3> <p>If you prefer publishing blog posts on medium.com or other external sources, starting version v0.5.0, <a href="https://github.com/alshedivat/al-folio">al-folio</a> lets you to display your external posts in the blog feed of your website! 🎉🎉</p> <p>Configuring external sources of super simple. After upgrading to v0.5.0, just add the following section to your _config.yml:</p> <pre>external_sources:<br />  - name: medium.com  # name of the source (arbitrary string)<br />    rss_url: <a href="https://medium.com/@al-folio/feed">https://medium.com/@&lt;your-medium-username&gt;/feed</a></pre> <p>The example above adds your medium.com blog post feed as an external source. But you can add arbitrary RSS feeds as sources.</p> <p>Any questions or suggestions? 👉 Start <a href="https://github.com/alshedivat/al-folio/discussions">a discussion on GitHub</a>!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b60a1d241a0a" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>